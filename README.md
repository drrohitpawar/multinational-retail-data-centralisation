# Multinational Retail Data Centralisation

## Project info:
I work for a multinational company that sells various goods across the globe.
Currently, their sales data is spread across many different data sources making it not easily accessible or analysable by current members of my team.
In an effort to become more data-driven, my organisation would like to make its sales data accessible from one centralised location.
My first goal will be to produce a system that stores the current company data in a database so that it can be accessed from one centralised location and acts as a single source of truth for sales data.
I will then query the database to get up-to-date metrics for the business.

## Instruction:
Download files to your own computer. \
Ensure all correct Python libraries are installed. \
Ensure credentials in upload_to_db function in database_utils are updated with the target database of your choice. \
Run all '_data' python files which will extract each table and upload to your database.

Once data is uploaded to your own Postgresql database, \
run all the SQL files in Database_Schema_SQL to further clean the data, set correct data types, and set primary and foreign keys. \
The file names describe their function.

Once the database is set up, you can start querying the data to gather some insights. \
There is a folder named Database_Query_SQL with 9 task SQL files. \
These contain some example queries. Each file starts with a comment describing the question the query answers.


